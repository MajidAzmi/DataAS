{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset Used here can be found on http://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2\n",
      "0.6374354064424276\n",
      "Testing R2\n",
      "0.5022375995887227\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "demo = pd.read_csv(\"concrete.csv\")\n",
    "X=demo.drop('strength',axis=1)\n",
    "y=demo['strength']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=10)\n",
    "lr=LinearRegression()\n",
    "lr.fit(Xtrain,ytrain)\n",
    "print(\"Training R2\")\n",
    "print(lr.score(Xtrain,ytrain))\n",
    "print(\"Testing R2\")\n",
    "print(lr.score(Xtest,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to eliminate the bias of random_state, We use cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresdt = cross_val_score(lr, Xtrain, ytrain, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52571613, 0.71904056, 0.62260097, 0.64177363, 0.71449256,\n",
       "       0.70070694, 0.58346583, 0.52009653, 0.65254622, 0.50414244])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618458179800325\n",
      "0.07771466904055849\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scoresdt))#this tells about Bias Error\n",
    "print(np.std(scoresdt))#Variance Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Polynomial Features and using PCA to improve the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As creating Polynomial features will make the relationship between features more linear\n",
    "## And PCA will remove the noise(i.e.,Multicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_csv(\"concrete.csv\")\n",
    "X=demo.drop('strength',axis=1)\n",
    "y=demo['strength']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=10)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "pca = PCA(n_components=128)\n",
    "sc=StandardScaler()\n",
    "scaledXtrain = sc.fit_transform(Xtrain)\n",
    "scaledXtest = sc.transform(Xtest)\n",
    "polyscaledXtrain = poly.fit_transform(scaledXtrain)\n",
    "polyscaledXtest = poly.transform(scaledXtest)\n",
    "pcaXtrain = pca.fit_transform(polyscaledXtrain)\n",
    "pcaXtest = pca.transform(polyscaledXtest)\n",
    "lr=LinearRegression()\n",
    "scores = cross_val_score(lr,Xtrain,ytrain,cv=10)\n",
    "scoresdt = cross_val_score(lr, polyscaledXtrain, ytrain, cv=10)\n",
    "lrpca=LinearRegression()\n",
    "scoresdtpca = cross_val_score(lrpca, pcaXtrain, ytrain, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Before Extracting polynomial features\n",
      "0.618458179800325\n",
      "Score After Extracting polynomial features\n",
      "0.8332261105080546\n",
      "Score After PCA\n",
      "0.8514289844107281\n"
     ]
    }
   ],
   "source": [
    "print('Score Before Extracting polynomial features')\n",
    "print(np.mean(scores))\n",
    "print(\"Score After Extracting polynomial features\")\n",
    "print(np.mean(scoresdt))\n",
    "print(\"Score After PCA\")\n",
    "print(np.mean(scoresdtpca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here We can see that just by creating polynomial features and PCA , How the performance of a simple linear regression model is improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pipeline for the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After PCA Avg Cross Val R2\n",
      "0.8516050336241344\n"
     ]
    }
   ],
   "source": [
    "#With Pipeline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "demo = pd.read_csv(\"concrete.csv\")\n",
    "X=demo.drop('strength',axis=1)\n",
    "y=demo['strength']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=10)\n",
    "pipe = Pipeline((\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"poly\",PolynomialFeatures(degree=3)),\n",
    "(\"pca\",PCA(n_components=128)),\n",
    "(\"rf\", LinearRegression()),\n",
    "))\n",
    "scoresdtpipe = cross_val_score(pipe, Xtrain, ytrain, cv=10)\n",
    "print(\"After PCA Avg Cross Val R2\")\n",
    "print(np.mean(scoresdtpipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model R2 on test data after fitting only on train data\n",
      "0.8915097013812546\n"
     ]
    }
   ],
   "source": [
    "print(\"Final model R2 on test data after fitting only on train data\")\n",
    "pipe.fit(Xtrain,ytrain)\n",
    "print(pipe.score(Xtest,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we used only linear regression to show how this techniques improve the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model performance will further increase if we go for complex models!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
